{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking and Detection in Computer Vision Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "#import tensorflow as tf\n",
    "#import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "import props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/thomala/Documents/TDCV-misc/ex3/dataset/\n",
      "C:/Users/thomala/Documents/TDCV-misc/ex3/preprocessing/\n"
     ]
    }
   ],
   "source": [
    "print(props.DATA_ROOT)\n",
    "print(props.DATA_PREP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the images and quaternions into datasets\n",
    "\n",
    "_You need to read the images together with the poses (stored in quaternions) and construct 3 datasets:\n",
    "the training set $S_{train}$ (train subset of the real folder and fine folder), test set $S_{test}$ (test\n",
    "subset of the real folder) and database set $S_{db}$ (\"coarse\" folder)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_normalize_image(img_path):\n",
    "    img = misc.imread(img_path)\n",
    "    img_norm = (img - np.mean(img,axis=(0,1)))/np.std(img,axis=(0,1))\n",
    "    return img_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_folder(folder_path, mask=[], direct=False):\n",
    "    # gets the images in folder folder_path that are also in mask,\n",
    "    # or if direct=False the images that are not in mask\n",
    "    directory = os.fsencode(folder_path)\n",
    "    image_files = []\n",
    "    quaternions = []\n",
    "    real_mask = []\n",
    "    \n",
    "    counter = 0\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        filepath = os.fsdecode(os.path.join(directory, file))\n",
    "        if filename.endswith(\".png\"): \n",
    "            if (direct and counter in mask) or not (direct or counter in mask):\n",
    "                image_files.append(load_and_normalize_image(filepath))\n",
    "                real_mask.append(counter)\n",
    "            counter += 1\n",
    "        elif 'poses.txt' in filename:\n",
    "            quaternions = [[float(s) for s in line.split()]\\\n",
    "                     for line in open(filepath).readlines()[1::2]]\n",
    "    \n",
    "    return image_files, [quaternions[i] for i in real_mask]    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n",
      "262\n",
      "5\n",
      "267\n",
      "262\n",
      "5\n",
      "[-0.21679691686430014, -0.5855909685700639, 0.7631570083471646, -0.16635412522060855]\n",
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1): # just to avoid creating useless global variables\n",
    "    i1, q1 = read_folder(props.DATA_ROOT + 'coarse/ape/')\n",
    "    i2, q2 = read_folder(props.DATA_ROOT + 'coarse/ape/', [2,3,5,7,9])\n",
    "    i3, q3 = read_folder(props.DATA_ROOT + 'coarse/ape/', [2,3,5,7,9], True)\n",
    "    print (len(i1))\n",
    "    print (len(i2))\n",
    "    print (len(i3))\n",
    "    print (len(q1))\n",
    "    print (len(q2))\n",
    "    print (len(q3))\n",
    "    print (q2[0])\n",
    "    print (np.shape(i2[0]))\n",
    "    #print(i2[0][::8,::8,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the 3 datasets and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.images = []\n",
    "        self.quats = []\n",
    "    \"\"\" >> TODO make these work\n",
    "    def add_image(img, quat, self):\n",
    "        self.images.append(img)\n",
    "        self.quats.append(quat)\n",
    "    \n",
    "    def get_image(i, self):\n",
    "        img = self.images[i]\n",
    "        quat = self.quats[i]\n",
    "        return img, quat\n",
    "    \n",
    "    def add_data(imgs, quats, self):\n",
    "        for img, quat in imgs, quats:\n",
    "            self.add_image(img, quat)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Remove real/duck/real1178-1252, we don't have their poses!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CLASSES = ['ape', 'benchvise', 'cam', 'cat', 'duck']\n",
    "\n",
    "print(\"[WARNING] Remove real/duck/real1178-1252, we don't have their poses!\")\n",
    "\n",
    "S_TRAIN = Dataset()\n",
    "\n",
    "S_TEST = Dataset()\n",
    "\n",
    "S_DB = Dataset()\n",
    "\n",
    "TRAIN_MASK = [int(s) for s in open(props.DATA_ROOT + 'real/training_split.txt')\\\n",
    "               .readlines()[0].split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ape\n",
      "benchvise\n",
      "cam\n",
      "cat\n",
      "duck\n"
     ]
    }
   ],
   "source": [
    "for class_name in CLASSES:\n",
    "    print(class_name)\n",
    "    img_db, quat_db = read_folder(props.DATA_ROOT + 'coarse/' + class_name + '/')\n",
    "    img_fn, quat_fn = read_folder(props.DATA_ROOT + 'fine/' + class_name + '/')\n",
    "    img_tn, quat_tn = read_folder(props.DATA_ROOT + 'real/' + class_name + '/',\n",
    "                                 TRAIN_MASK, True)\n",
    "    img_ts, quat_ts = read_folder(props.DATA_ROOT + 'real/' + class_name + '/',\n",
    "                                 TRAIN_MASK, False)\n",
    "    \n",
    "    \n",
    "    for img in img_db:\n",
    "        S_DB.images.append(img)\n",
    "    for quat in quat_db:\n",
    "        S_DB.quats.append(quat)\n",
    "    for img in img_fn:\n",
    "        S_TRAIN.images.append(img)\n",
    "    for quat in quat_fn:\n",
    "        S_TRAIN.quats.append(quat)\n",
    "    for img in img_tn:\n",
    "        S_TRAIN.images.append(img)\n",
    "    for quat in quat_tn:\n",
    "        S_TRAIN.quats.append(quat)\n",
    "    for img in img_ts:\n",
    "        S_TEST.images.append(img)\n",
    "    for quat in quat_ts:\n",
    "        S_TEST.quats.append(quat)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sizes of the datasets\n",
    "\n",
    "Should be 2-by-2 equal, images contain $64 \\times 64 \\times 3$ arrays, quaternions contain 4 coordinates, and sizes be 1335 for DB, 7410 for TRAIN and 3535 for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1335, 64, 64, 3)\n",
      "(1335, 4)\n",
      "(7410, 64, 64, 3)\n",
      "(7410, 4)\n",
      "(3535, 64, 64, 3)\n",
      "(3535, 4)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(S_DB.images))\n",
    "print (np.shape(S_DB.quats))\n",
    "print (np.shape(S_TRAIN.images))\n",
    "print (np.shape(S_TRAIN.quats))\n",
    "print (np.shape(S_TEST.images))\n",
    "print (np.shape(S_TEST.quats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch generator - TODO not random yet\n",
    "\n",
    "_The batch generator should be able to construct batches of triplets that are\n",
    "later fed to the network. Each triplet consists of 3 samples: anchor, puller, and\n",
    "pusher. Anchor is chosen randomly from the training set $S_{train}$. Puller is the most similar\n",
    "(quaternion-wise) to anchor sample of the same object taken from the db set $S_{db}$. Finally, there are 2 types of pushers: it can either be the same object but a different\n",
    "from puller pose or a randomly chosen different object. Pushers are also drawn from $S_{db}$_\n",
    "\n",
    "### Create a random batch element following these requirements\n",
    "\n",
    "Since quaterions in our case are of unit norm, their dot product is always in [0;1] in absolute value. Since arccos is strictly non-decreasing over [0;1], minimizing the quaternion angular metric $\\theta(q_1, q_2) = 2 arccos(|q_1.q_2|)$ is strictly equivalent to maximizing their dot product, which is what we do to find the puller, for obvious speed reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_puller(quat):\n",
    "    best_puller = 0\n",
    "    best_result = 0\n",
    "    for index in range(len(S_DB.quats)):\n",
    "        current_result = abs(np.dot(quat, S_DB.quats[index]))\n",
    "        if current_result > best_result:\n",
    "            best_puller = index\n",
    "            best_result = current_result\n",
    "    return best_puller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Sanity check :p\n",
    "print(find_puller(S_DB.quats[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_pusher(index, change_pose=0.5):\n",
    "    nb_poses_per_object = len(S_DB.quats) // 5\n",
    "    if (random.random() > change_pose): # TODO replace by the python for `rand()/randmax>change_pose`\n",
    "        # then find another image with the same pose:\n",
    "        # since all objects have the poses in the same order, this implies\n",
    "        # looking for (index + R * N_DB / 5) % N_DB, where R is randomly\n",
    "        # chosen in [1;4]\n",
    "        R = random.randrange(1,5)\n",
    "        return (index + R * nb_poses_per_object) % len(S_DB.quats)\n",
    "    else:\n",
    "        # then find another pose for the same image:\n",
    "        # looking for a random number in index's interval [A,A+1]*N_DB/5\n",
    "        # that isn't index, so basically (index + R) % N_DB/5 + A*N_DB/5\n",
    "        # where R is randomly drawn in [1;N_DB/5]\n",
    "        R = random.randrange(1,nb_poses_per_object)\n",
    "        A = index // nb_poses_per_object\n",
    "        return (index + R) % nb_poses_per_object + A * nb_poses_per_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of poses per object:\t267\n",
      "Same pose, all objects are:\t58\t325\t592\t859\t1126\t\n",
      "Same object, different poses are in:\t267\t534\n",
      "Pusher examples:\t526\t58\t447\t1126\t309\t592\t374\t487\t592\t592\t442\t592\t330\t592\t443\t505\t58\t592\t859\t411\t411\t1126\t58\t296\t381\t859\t513\t505\t430\t859\t384\t1126\t592\t520\t592\t485\t58\t300\t1126\t342\t274\t1126\t367\t336\t859\t328\t859\t504\t58\t487\t859\t58\t58\t444\t1126\t592\t859\t488\t520\t475\t58\t294\t366\t475\t859\t381\t307\t404\t359\t859\t377\t58\t1126\t492\t273\t488\t859\t859\t859\t592\t58\t1126\t592\t393\t592\t369\t299\t358\t592\t360\t592\t859\t859\t399\t592\t859\t1126\t592\t479\t285\t"
     ]
    }
   ],
   "source": [
    "print(\"Number of poses per object:\\t\"+str(len(S_DB.quats) // 5))\n",
    "print(\"Same pose, all objects are:\", end='\\t', flush=True)\n",
    "for i in range(5):\n",
    "    print(i * (len(S_DB.quats) // 5) + 325 % (len(S_DB.quats) // 5), end='\\t', flush=True)\n",
    "print(\"\\nSame object, different poses are in:\", end='\\t', flush=True)\n",
    "for i in range(1):\n",
    "    N = len(S_DB.quats) // 5\n",
    "    print(str((325 // N)*N) + \"\\t\" + str((1 + 325 // N)*(N)) + \"\\nPusher examples:\", end='\\t', flush=True)\n",
    "for i in range(100):\n",
    "    print(find_pusher(325), end='\\t', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_batch(change_pose=0.5):\n",
    "    anchor = random.randrange(0, len(S_TRAIN.quats))\n",
    "    puller = find_puller(S_TRAIN.quats[anchor])\n",
    "    pusher = find_pusher(puller, change_pose)\n",
    "    return anchor, puller, pusher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5514, 35, 46)   (144, 48, 582)   (3374, 28, 562)   (5645, 237, 1038)   (6869, 254, 250)   (4331, 46, 847)   (6732, 226, 1027)   (6665, 200, 198)   (2798, 4, 141)   (864, 159, 29)   (4142, 228, 220)   (5213, 221, 488)   (2167, 199, 466)   (3740, 221, 488)   (1307, 148, 221)   (5259, 229, 146)   (37, 7, 170)   (2592, 229, 496)   (1356, 141, 942)   (5493, 111, 1179)   "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(find_batch(), end=\"   \", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the batch proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(batch_size, change_pose=0.5):\n",
    "    return [find_batch(change_pose)\n",
    "#TODO check it still works when random :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3884, 242, 1310, 3884, 242, 1310, 3884, 242, 1310, 3884, 242, 1310, 3884, 242, 1310)\n"
     ]
    }
   ],
   "source": [
    "print(generate_batch(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the batch - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jieneng's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-60c355c19c69>\", line 104, in <module>\n",
      "    coa_ape = load_img(\"/home/chen/exercise3/dataset/coarse/ape/\", \"coarse\", 266)\n",
      "  File \"<ipython-input-14-60c355c19c69>\", line 13, in __init__\n",
      "    img = misc.imread(imgpath)\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\site-packages\\scipy\\misc\\pilutil.py\", line 156, in imread\n",
      "    im = Image.open(name)\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 2477, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/chen/exercise3/dataset/coarse/ape/coarse0.png'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1806, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\inspect.py\", line 666, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\inspect.py\", line 709, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\inspect.py\", line 678, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\inspect.py\", line 663, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\thomala\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/chen/exercise3/dataset/coarse/ape/coarse0.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "class load_img:\n",
    "\n",
    "    ## load image of one class from one of three folder(coarse, fine, real)\n",
    "    ## the size of outputdata is (1178, 12292) containing 4 poses data and flatted normalized images data.\n",
    "    def __init__(self, folderName, className, endIdx):\n",
    "        imglist = []\n",
    "        # 64*64*3 = 12288\n",
    "        img_fla = []\n",
    "        for i in range(0, endIdx + 1):\n",
    "            i1 = str(i)\n",
    "            imgpath = folderName + className + i1 + \".png\"\n",
    "\n",
    "            img = misc.imread(imgpath)\n",
    "            imglist.append(img)\n",
    "\n",
    "            f_img = np.ndarray.flatten(img)\n",
    "            img_fla.append(f_img)\n",
    "\n",
    "        '''Normalize RGB channel to zero mean and unit variable'''\n",
    "        X = img_fla\n",
    "        X = np.double(X)\n",
    "        X -= np.mean(X, axis=0)\n",
    "        X /= np.std(X, axis=0)\n",
    "        nor_img = X\n",
    "\n",
    "        '''Load the poses.txt data and convert them to a 2D list'''\n",
    "        pos_path = folderName + \"poses.txt\"\n",
    "        pos_dat = open(pos_path, 'r')\n",
    "        a = pos_dat.read()\n",
    "        pos_dat = a.split()\n",
    "        ## the first 2 cols are # and \"reali.png\", which should be removed\n",
    "        pos_dat = np.reshape(pos_dat, (endIdx + 1, 6))\n",
    "        pos_dat = [[item for index, item in enumerate(items) if index != 0] for items in pos_dat]\n",
    "        pos_dat = [[item for index, item in enumerate(items) if index != 0] for items in pos_dat]\n",
    "\n",
    "        load_img.pos_list = []\n",
    "        for i in range(endIdx + 1):\n",
    "            a = list(map(float, pos_dat[i]))\n",
    "            load_img.pos_list.append(a)\n",
    "\n",
    "        load_img.data = []\n",
    "        nor_img = nor_img.tolist()\n",
    "        for i in range(endIdx + 1):\n",
    "            b = load_img.pos_list[i]\n",
    "            a = nor_img[i]\n",
    "            b.extend(a)\n",
    "            load_img.data.append(b)\n",
    "        print(\"the column of load_img.pos_list should be 4 instead of 12292, do you know why when I give the value of load_img.pos_list to b, and it will be changed as b change?\")\n",
    "        print(np.shape(load_img.pos_list))\n",
    "\n",
    "    def loa_img(self):\n",
    "        dat = load_img.data\n",
    "        return dat\n",
    "\n",
    "    def loa_pos(self):\n",
    "        pos_list = load_img.pos_list\n",
    "        return pos_list\n",
    "\n",
    "\n",
    "    def tra_img(self):\n",
    "        spl_path = \"/home/chen/exercise3/dataset/real/training_split.txt\"\n",
    "        spl_indice = open(spl_path, 'r')\n",
    "        a = spl_indice.read()\n",
    "        b = a.split(\",\")\n",
    "        ind_list = list(map(int, b))\n",
    "        # len = len(ind_list)\n",
    "        tra_img = []\n",
    "        for i in ind_list:\n",
    "            tra = load_img.data[i]\n",
    "            tra_img.append(tra)\n",
    "        return tra_img\n",
    "\n",
    "    def tra_pos(self):\n",
    "        spl_path = \"/home/chen/exercise3/dataset/real/training_split.txt\"\n",
    "        spl_indice = open(spl_path, 'r')\n",
    "        a = spl_indice.read()\n",
    "        b = a.split(\",\")\n",
    "        ind_list = list(map(int, b))\n",
    "        # len = len(ind_list)\n",
    "        tra_pos = []\n",
    "        for i in ind_list:\n",
    "            tra = load_img.pos_list[i]\n",
    "            tra_pos.append(tra)\n",
    "        return tra_pos\n",
    "\n",
    "    def tes_img(self):\n",
    "        spl_path = \"/home/chen/exercise3/dataset/real/training_split.txt\"\n",
    "        spl_indice = open(spl_path, 'r')\n",
    "        a = spl_indice.read()\n",
    "        b = a.split(\",\")\n",
    "        ind_list = list(map(int, b))\n",
    "        tes_img = []\n",
    "        for i in range(1178):\n",
    "            tes = load_img.data[i]\n",
    "            for j in ind_list:\n",
    "                if (i != j):\n",
    "                    tes_img.append(tes)\n",
    "        return tes_img\n",
    "\n",
    "\n",
    "\n",
    "## should I use dictionary?\n",
    "'''the shape of coa_ape(example) should be 266*12292'''\n",
    "coa_ape = load_img(\"/home/chen/exercise3/dataset/coarse/ape/\", \"coarse\", 266)\n",
    "coa_ben = load_img(\"/home/chen/exercise3/dataset/coarse/benchvise/\", \"coarse\", 266)\n",
    "coa_cam = load_img(\"/home/chen/exercise3/dataset/coarse/cam/\", \"coarse\", 266)\n",
    "coa_cat = load_img(\"/home/chen/exercise3/dataset/coarse/cat/\", \"coarse\", 266)\n",
    "coa_duc = load_img(\"/home/chen/exercise3/dataset/coarse/duck/\", \"coarse\", 266)\n",
    "\n",
    "'''5*267*12292'''\n",
    "S_db = []\n",
    "S_db.extend(coa_ape.loa_img())\n",
    "S_db.extend(coa_ben.loa_img())\n",
    "S_db.extend(coa_cam.loa_img())\n",
    "S_db.extend(coa_cat.loa_img())\n",
    "S_db.extend(coa_duc.loa_img())\n",
    "print(\"the shape of S_db:\")\n",
    "print(np.shape(S_db))\n",
    "\n",
    "S_db_pos = []\n",
    "S_db_pos.extend(coa_ape.loa_pos())\n",
    "S_db_pos.extend(coa_ben.loa_pos())\n",
    "S_db_pos.extend(coa_cam.loa_pos())\n",
    "S_db_pos.extend(coa_cat.loa_pos())\n",
    "S_db_pos.extend(coa_duc.loa_pos())\n",
    "print(\"the shape of S_db_pos:\")\n",
    "print(np.shape(S_db_pos))\n",
    "\n",
    "fin_ape = load_img(\"/home/chen/exercise3/dataset/fine/ape/\", \"fine\", 1010)\n",
    "fin_ben = load_img(\"/home/chen/exercise3/dataset/fine/benchvise/\", \"fine\", 1010)\n",
    "fin_cam = load_img(\"/home/chen/exercise3/dataset/fine/cam/\", \"fine\", 1010)\n",
    "fin_cat = load_img(\"/home/chen/exercise3/dataset/fine/cat/\", \"fine\", 1010)\n",
    "fin_duc = load_img(\"/home/chen/exercise3/dataset/fine/duck/\", \"fine\", 1010)\n",
    "\n",
    "\n",
    "print(np.shape(fin_ape.loa_img()))\n",
    "\n",
    "rea_ape = load_img(\"/home/chen/exercise3/dataset/real/ape/\", \"real\", 1177)\n",
    "rea_ben = load_img(\"/home/chen/exercise3/dataset/real/benchvise/\", \"real\", 1177)\n",
    "rea_cam = load_img(\"/home/chen/exercise3/dataset/real/cam/\", \"real\", 1177)\n",
    "rea_cat = load_img(\"/home/chen/exercise3/dataset/real/cat/\", \"real\", 1177)\n",
    "rea_duc = load_img(\"/home/chen/exercise3/dataset/real/duck/\", \"real\", 1177)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# S_tra = []\n",
    "# tra_ape = rea_ape.tra_img()\n",
    "# tra_ben = rea_ape.tra_img()\n",
    "# tra_cam = rea_ape.tra_img()\n",
    "# tra_cat = rea_ape.tra_img()\n",
    "# tra_duc = rea_ape.tra_img()\n",
    "\n",
    "# S_tra.append(fin_ape.loa_img())\n",
    "# S_tra.append(tra_ape)\n",
    "# S_tra.append(fin_ben.loa_img())\n",
    "# S_tra.append(tra_ben)\n",
    "# S_tra.append(fin_cam.loa_img())\n",
    "# S_tra.append(tra_cam)\n",
    "# S_tra.append(fin_cat.loa_img())\n",
    "# S_tra.append(tra_cat)\n",
    "# S_tra.append(fin_duc.loa_img())\n",
    "# S_tra.append(tra_duc)\n",
    "#\n",
    "# S_tra_pos= []\n",
    "# tra_ape = rea_ape.tra_pos()\n",
    "# tra_ben = rea_ben.tra_pos()\n",
    "# tra_cam = rea_cam.tra_pos()\n",
    "# tra_cat = rea_cat.tra_pos()\n",
    "# tra_duc = rea_duc.tra_pos()\n",
    "#\n",
    "# S_tra.append(fin_ape.loa_pos())\n",
    "# S_tra.append(tra_ape)\n",
    "# S_tra.append(fin_ben.loa_pos())\n",
    "# S_tra.append(tra_ben)\n",
    "# S_tra.append(fin_cam.loa_pos())\n",
    "# S_tra.append(tra_cam)\n",
    "# S_tra.append(fin_cat.loa_pos())\n",
    "# S_tra.append(tra_cat)\n",
    "# S_tra.append(fin_duc.loa_pos())\n",
    "# S_tra.append(tra_duc)\n",
    "\n",
    "#print(np.shape(S_tra))\n",
    "\n",
    "S_tes = []\n",
    "S_tes.append(rea_ape)\n",
    "S_tes.append(rea_ben)\n",
    "S_tes.append(rea_cam)\n",
    "S_tes.append(rea_cat)\n",
    "S_tes.append(rea_duc)\n",
    "tes_ape = rea_ape.tes_img()\n",
    "tes_ben = rea_ape.tes_img()\n",
    "tes_cam = rea_ape.tes_img()\n",
    "tes_cat = rea_ape.tes_img()\n",
    "tes_duc = rea_ape.tes_img()\n",
    "S_tes.append(tes_ape)\n",
    "S_tes.append(tes_ben)\n",
    "S_tes.append(tes_cam)\n",
    "S_tes.append(tes_cat)\n",
    "S_tes.append(tes_duc)\n",
    "\n",
    "\n",
    "\n",
    "#n = np.shape(S_tra)\n",
    "#print(n)\n",
    "#print(np.shape(tra_duc))\n",
    "\n",
    "\n",
    "'''input the pos_list containing only  quaternion poses of S_db'''\n",
    "'''output is a 2D list, each row contain a indice of a pose from'''\n",
    "'''S_db and a indice of another similar pose to find puller'''\n",
    "def similarity(S_db_pos, S_tra_pos):\n",
    "    #In the data set of S_db, find the one which is most similar to the other one\n",
    "    theta = []\n",
    "    sim_ind = [[]]\n",
    "    for i in len(S_db_pos):\n",
    "        for j in len(S_tra_pos):\n",
    "            theta[i] = np.arccos(abs(S_db_pos[i] * S_tra_pos[j]))\n",
    "            if(theta[i] < a):\n",
    "                a = theta[i]\n",
    "                sim_ind[i] = i\n",
    "                sim_ind[i].append(j)\n",
    "    return sim_ind\n",
    "\n",
    "\n",
    "'''need to create a 3D list to put the batches in??'''\n",
    "def batch_generator(S_db, S_tra, n):\n",
    "\n",
    "    len_db = len(S_db)\n",
    "    len_tra = len(S_tra)\n",
    "    gen_ind_tra = np.arrange(len_tra)\n",
    "    gen_ind_tra = np.random.shuffle(gen_ind_tra)\n",
    "    gen_ind_tra = gen_ind_tra[0:n]\n",
    "\n",
    "    sim_ind = similarity(S_db_pos, S_tra_pos)\n",
    "\n",
    "    batch = []\n",
    "    for i in gen_ind_tra:\n",
    "        anchor = S_tra[i]\n",
    "        ##first dimension is anchor from S_tra, second is puller from S_db\n",
    "        batch.append(anchor)\n",
    "        puller = S_db[(sim_ind[i][1])]\n",
    "        batch.append(puller)\n",
    "        ##there are 2 types of pushers: it can either be the same object but a different\n",
    "        ## from puller pose or a randomly chosen different object from S_db\n",
    "        '''hypothesis that the shape of S_db is 5*267*12292'''\n",
    "        gen_ind_db_cla = np.random.randint(5)\n",
    "        gen_ind_db = np.random.shuffle(gen_ind_db_cla)\n",
    "        if(S_db[gen_ind_db_cla][gen_ind_db] != puller):\n",
    "            pusher = S_db[gen_ind_db_cla][gen_ind_db]\n",
    "        batch.append(pusher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
